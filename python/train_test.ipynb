{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savez = np.load(\"/home/gnlenfn/data/remote/pytorch_emotion/Feature/data_save.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savez['x'].shape\n",
    "savez['y'].shape\n",
    "savez['s'].shape\n",
    "savez['t'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(savez['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.where(savez['y'] == 'exc', 'hap', savez['y'])\n",
    "#savez['y'][exc] = 'hap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../Feature/emotion_classes.csv\")\n",
    "df.EMOTION.value_counts()                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "for i in range(df.shape[0]):\n",
    "    if df.TURN_NAME[i][7:12]=='impro':\n",
    "        k.append(df.EMOTION[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = np.where(savez['t'] == 'impro')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savez['t'][~imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = savez['x'][imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[imp].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exc = np.where(k[imp] == 'exc')[0]\n",
    "hap = np.where(k[imp] == 'hap')[0]\n",
    "ang = np.where(k[imp] == 'ang')[0]\n",
    "neu = np.where(k[imp] == 'neu')[0]\n",
    "sad = np.where(k[imp] == 'sad')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hap.shape[0] + ang.shape[0] + neu.shape[0] +sad.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = savez['x'][imp]\n",
    "y_data = k[imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2942,)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.where((savez['s'] == \"Ses05\") & (savez['t'] == 'impro'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = [x for x in range(x_data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.isin(val_idx, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2942,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2421,) (2421,)\n"
     ]
    }
   ],
   "source": [
    "speak = ['Ses01']#, 'Ses02', 'Ses03', 'Ses04', 'Ses05'] # cross validation\n",
    "avg_acc = 0\n",
    "\n",
    "is_train_set = True\n",
    "for sp in speak:\n",
    "    savez = np.load(\"/home/gnlenfn/data/remote/pytorch_emotion/Feature/data_save.npz\", allow_pickle=True)\n",
    "    total_idx = [x for x in range(savez['x'].shape[0])]\n",
    "    if is_train_set == False:\n",
    "        idx = np.where((savez['s'] == sp) & (savez['t'] == 'impro'))            \n",
    "    else: idx = np.where((savez['s'] != sp) & (savez['t'] == 'impro'))\n",
    "\n",
    "    x_data = savez['x'][idx]\n",
    "    k = np.where(savez['y'] == 'exc', 'hap', savez['y'])\n",
    "    y_data = k[idx]\n",
    "    \n",
    "    print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_data = le.fit_transform(y_data)\n",
    "y_data = to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.expand_dims(x_data[0], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "532\n",
      "2942\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for X, Y in zip(x_data, y_data):\n",
    "    \n",
    "    tmp = X.shape\n",
    "    if tmp[0] == 0:\n",
    "        print(\"x\")\n",
    "        print(c)\n",
    "    c += 1\n",
    "        \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.delete(x_data, 11)\n",
    "new_y = np.delete(y_data, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "for i in range(len(new_x)):\n",
    "    \n",
    "    k.append(new_x[i].reshape(-1))\n",
    "k = np.array(k)\n",
    "X_train = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "__________________________________________________________________________________________\n",
      "Layer (type)                            Output Shape                        Param #       \n",
      "==========================================================================================\n",
      "lstm_66 (LSTM)                          (None, None, 32)                    8320          \n",
      "__________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (GlobalAver (None, 32)                          0             \n",
      "__________________________________________________________________________________________\n",
      "dense_43 (Dense)                        (None, 4)                           132           \n",
      "==========================================================================================\n",
      "Total params: 8,452\n",
      "Trainable params: 8,452\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 301ms/step - loss: 0.9207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.6744\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 276ms/step - loss: 2.5510\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 346ms/step - loss: 0.5573\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.5060\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 413ms/step - loss: 0.4355\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 590ms/step - loss: 1.9351\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 497ms/step - loss: 0.4175\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 4s 752ms/step - loss: 0.2568\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.2244\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 467ms/step - loss: 2.3126\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 467ms/step - loss: 0.2678\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.2805\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 342ms/step - loss: 1.8609\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 315ms/step - loss: 0.3833\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 345ms/step - loss: 1.1416\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.4775\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 487ms/step - loss: 0.5521\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 584ms/step - loss: 0.4230\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 281ms/step - loss: 0.3524\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.3078\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 529ms/step - loss: 1.9608\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.2313\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 1.7450\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 366ms/step - loss: 0.2754\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 455ms/step - loss: 0.3795\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 367ms/step - loss: 0.4137\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 269ms/step - loss: 1.5145\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 296ms/step - loss: 0.3541\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.3619\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 335ms/step - loss: 0.3343\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 343ms/step - loss: 0.2891\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 335ms/step - loss: 0.2046\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2171\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 1.8721\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.2613\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.3773\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 265ms/step - loss: 0.2765\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 1.4926\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 465ms/step - loss: 0.3240\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.3022\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.3297\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 1.1391\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.3943\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 364ms/step - loss: 0.4182\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 327ms/step - loss: 1.3545\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2768\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.3415\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.2641\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1752\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 1.7266\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.2607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.1335\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 326ms/step - loss: 0.2779\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 267ms/step - loss: 1.1777\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 404ms/step - loss: 0.4008\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.2006\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 1.6349\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 283ms/step - loss: 0.5101\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.3870\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.3373\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2634\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 345ms/step - loss: 1.5191\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 273ms/step - loss: 0.3113\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.3070\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3235\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 1.5428\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.1703\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 322ms/step - loss: 0.1323\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 327ms/step - loss: 0.2124\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 2.2402\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.2112\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.2108\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.2006\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 329ms/step - loss: 1.4320\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 309ms/step - loss: 0.2863\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1452\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.2585\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 1.7301\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 302ms/step - loss: 0.3530\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.4614\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2828\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 1.8244\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.3800\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 312ms/step - loss: 0.3660\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 1.3474\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 407ms/step - loss: 0.3791\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 264ms/step - loss: 0.2754\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.2566\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.3448\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.7712\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 306ms/step - loss: 0.2391\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3065\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 1.6058\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2989\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.3220\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.4045\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.2083\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 267ms/step - loss: 1.3346\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.2505\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.2738\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 534ms/step - loss: 0.3108\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 488ms/step - loss: 1.2212\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.2619\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.3127\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 430ms/step - loss: 0.2809\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 1.3374\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.3407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 690ms/step - loss: 0.4403\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.2234\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 343ms/step - loss: 1.6551\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.2473\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.2294\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2136\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 1.4581\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2540\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.3573\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.2087\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 1.4765\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 539ms/step - loss: 0.3595\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.3260\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 366ms/step - loss: 0.3785\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 1.5408\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.3406\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 288ms/step - loss: 0.3460\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 680ms/step - loss: 1.2342\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.3840\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.3445\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 320ms/step - loss: 0.4056\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 346ms/step - loss: 0.3381\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 1.5319\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.3785\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.3114\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.3070\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 1.6948\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.2764\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 268ms/step - loss: 0.3198\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 1.2933\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.3161\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.4383\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.3684\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.3085\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.3644\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 288ms/step - loss: 0.3178\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.6080\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 403ms/step - loss: 0.2923\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.3347\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 424ms/step - loss: 0.2800\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 435ms/step - loss: 1.3510\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.3103\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.3255\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.2777\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.2757\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.2985\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 584ms/step - loss: 0.3124\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 457ms/step - loss: 0.2699\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 1.4779\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.3236\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.3220\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 534ms/step - loss: 0.2431\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 467ms/step - loss: 1.5377\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2662\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 423ms/step - loss: 0.2987\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.2455\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 273ms/step - loss: 1.3865\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 468ms/step - loss: 0.3066\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 329ms/step - loss: 0.2550\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.2618\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 463ms/step - loss: 1.4089\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 451ms/step - loss: 0.2372\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.2936\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2642\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 1.9767\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 481ms/step - loss: 0.3071\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 4s 868ms/step - loss: 0.2106\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 595ms/step - loss: 0.2260\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 4s 734ms/step - loss: 1.8187\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 567ms/step - loss: 0.2100\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 410ms/step - loss: 0.2047\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2336\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 653ms/step - loss: 1.5332\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.2489\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.2394\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.2263\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 536ms/step - loss: 1.4610\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 500ms/step - loss: 0.3373\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.2483\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3182\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.4490\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 353ms/step - loss: 0.3408\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 291ms/step - loss: 0.2823\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 498ms/step - loss: 0.2952\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.3068\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 636ms/step - loss: 1.5247\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 452ms/step - loss: 0.2088\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.2784\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.1774\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 480ms/step - loss: 1.7723\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.2034\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 442ms/step - loss: 0.2663\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.2183\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.6670\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.2833\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.2564\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 1.2870\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2710\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.2671\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.2518\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.2213\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 1.5832\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.3583\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.2485\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.2331\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 482ms/step - loss: 1.0295\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 5s 905ms/step - loss: 0.4468\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.5816\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 392ms/step - loss: 0.9582\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.5296\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.4261\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 272ms/step - loss: 0.3903\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 454ms/step - loss: 1.2433\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 534ms/step - loss: 0.3333\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 655ms/step - loss: 0.3160\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.2525\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 316ms/step - loss: 1.3244\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 364ms/step - loss: 0.5711\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 527ms/step - loss: 0.3562\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 584ms/step - loss: 0.2946\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 417ms/step - loss: 0.2980\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 414ms/step - loss: 1.5028\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 653ms/step - loss: 0.2895\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.2740\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 457ms/step - loss: 0.3382\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 332ms/step - loss: 1.5780\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.3190\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 377ms/step - loss: 0.2576\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 1.3848\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 274ms/step - loss: 0.3999\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 346ms/step - loss: 0.2947\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 5s 954ms/step - loss: 0.2842\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.2314\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 1.4087\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.2564\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 286ms/step - loss: 0.2297\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 1.2613\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.2248\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 275ms/step - loss: 0.2164\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.2728\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 368ms/step - loss: 0.2821\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 4s 779ms/step - loss: 1.4669\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 281ms/step - loss: 0.2634\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 270ms/step - loss: 0.2743\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.1412\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 1.6975\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 273ms/step - loss: 0.2764\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.3263\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3377\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 1.3455\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 419ms/step - loss: 0.3188\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.2371\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 1.3247\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.3603\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 299ms/step - loss: 0.3656\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.3092\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 362ms/step - loss: 1.3425\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.2758\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2616\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.2287\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 1.6565\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.2366\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 339ms/step - loss: 0.2782\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.2890\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.2381\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 1.7266\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2400\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.2310\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 341ms/step - loss: 0.2209\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 1.6640\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.2504\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 276ms/step - loss: 0.2730\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.2459\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 1.5626\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2704\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.2849\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.3224\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 1.2596\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.2634\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.2962\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 1.0596\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.4165\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 276ms/step - loss: 0.4280\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.5196\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 1.0079\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 293ms/step - loss: 0.3121\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.3477\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 436ms/step - loss: 0.3064\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 335ms/step - loss: 0.2793\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 303ms/step - loss: 1.5341\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2278\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.2973\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 281ms/step - loss: 0.3278\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 1.3831\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.2575\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.2291\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.2675\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 1.3963\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.2583\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.3126\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 312ms/step - loss: 0.2649\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 1.3999\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.3019\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.3259\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.1994\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 1.5757\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.2468\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.2897\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.3341\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 306ms/step - loss: 1.4498\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 318ms/step - loss: 0.3431\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 605ms/step - loss: 0.2926\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.3304\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 1.3156\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2743\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.3551\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.3047\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 1.8150\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.3066\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 482ms/step - loss: 1.2015\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.3089\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.3091\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.3453\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 363ms/step - loss: 1.3394\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 0.3453\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.3500\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.3746\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 1.3253\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.3821\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.4474\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.3913\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 1.4163\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 273ms/step - loss: 0.3405\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.4215\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2839\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 1.2755\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 312ms/step - loss: 0.3027\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 490ms/step - loss: 0.3367\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2790\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 1.4967\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.2993\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.2578\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2532\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.3092\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 338ms/step - loss: 0.2349\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 1.3765\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2795\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.2811\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 262ms/step - loss: 0.2214\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.7954\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.2588\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.2171\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 310ms/step - loss: 0.2686\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 1.6328\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2032\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.3179\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.2820\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 1.8477\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.3165\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1963\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.2707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.4308\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.3430\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.3320\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.2777\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.4034\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.3471\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 0.3126\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.2769\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 373ms/step - loss: 1.5151\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.2534\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.2501\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.3537\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 1.3785\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.2678\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2377\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.3047\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 1.4060\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.3188\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.2772\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2628\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 1.3989\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.3689\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3587\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.3535\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 1.1701\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.3221\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.3199\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.3194\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.4777\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.2949\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.2340\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2305\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 1.3290\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 0.2436\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.3071\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 281ms/step - loss: 0.3294\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 1.3656\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 290ms/step - loss: 0.2446\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.2330\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.2952\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 1.7160\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2541\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.2262\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.2172\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 1.4836\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.2767\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.3186\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.2752\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.5066\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2753\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2530\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.3450\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 1.5301\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2485\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.2880\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.2730\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 1.4476\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2586\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2930\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.3130\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 1.3787\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.3091\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.2643\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.2572\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 1.5004\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.2736\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2984\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2978\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.4339\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2696\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.2945\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.2320\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 1.5396\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2552\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.2790\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.2694\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 1.5008\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 562ms/step - loss: 0.2533\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.2774\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.2510\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 1.5575\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.2517\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 0.2872\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.2729\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 1.4604\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.2839\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.2634\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.2732\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 5s 958ms/step - loss: 1.4363\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.2679\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.2824\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.3236\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 1.4963\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.2905\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.3000\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.2754\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 1.3152\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.2722\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.2818\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.2805\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 1.4750\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 295ms/step - loss: 0.2778\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.3692\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 296ms/step - loss: 0.3403\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.1260\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.3090\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 1.4005\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.2993\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.2841\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.3234\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 1.4472\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.3496\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 0.3796\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.3027\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 1.2186\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 471ms/step - loss: 0.2271\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.3294\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 267ms/step - loss: 0.3246\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 1.3946\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.3122\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 313ms/step - loss: 0.2537\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.2466\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.3207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.2832\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.2905\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3269\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 464ms/step - loss: 1.5159\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.3888\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 419ms/step - loss: 0.2114\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.3271\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 269ms/step - loss: 1.2288\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.3022\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 514ms/step - loss: 0.2465\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.2486\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 353ms/step - loss: 1.6610\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.2775\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2215\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.2190\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 1.5409\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 508ms/step - loss: 0.2860\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.3624\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 469ms/step - loss: 0.1836\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.5205\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.2568\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.3115\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.2168\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 1.9670\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.1646\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.2369\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.2288\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 1.7974\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2511\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.2620\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.2537\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 1.5553\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 403ms/step - loss: 0.2795\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.2657\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.2201\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.6114\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.2449\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.2050\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.2170\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Tried to stack elements of an empty list with non-fully-defined element_shape: [?,32]\n\t [[node lstm_66/TensorArrayV2Stack/TensorListStack (defined at /home/gnlenfn/anaconda3/envs/nn/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_keras_scratch_graph_378328]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-49a300173d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print(Y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Tried to stack elements of an empty list with non-fully-defined element_shape: [?,32]\n\t [[node lstm_66/TensorArrayV2Stack/TensorListStack (defined at /home/gnlenfn/anaconda3/envs/nn/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_keras_scratch_graph_378328]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(None, 32)))\n",
    "#model.add(LSTM(8, return_sequences=True))\n",
    "#model.add(TimeDistributed(Dense(1)))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "print(model.summary(90))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "for X, Y in zip(new_x, new_y):\n",
    "    X = K.expand_dims(X, axis=0)\n",
    "    Y = K.expand_dims(Y, axis=0)\n",
    "    #print(Y.shape)\n",
    "    model.fit(X, Y, verbose=1, steps_per_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"best model: {}: {:4f}%\".format(loaded_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torchvision.datasets as dsets \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn import preprocessing\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureData(Dataset):        \n",
    "    def __init__(self, is_train_set=False, transforms=None):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "\n",
    "        total_idx = [x for x in range(savez['x'].shape[0])]\n",
    "        if is_train_set == False:\n",
    "            idx = np.where((savez['s'] == \"Ses01\") & (savez['t'] == 'impro'))            \n",
    "        else: idx = np.where((savez['s'] != \"Ses01\") & (savez['t'] == 'impro'))\n",
    "\n",
    "        self.x_data = savez['x'][idx]\n",
    "        k = np.where(savez['y'] == 'exc', 'hap', savez['y'])\n",
    "        self.y_data = k[idx]\n",
    "        self.y_data = le.fit_transform(self.y_data)\n",
    "        self.len = self.x_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = FeatureData(is_train_set=False)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_dim, num_layers=self.num_layers)\n",
    "        self.hidden = None\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        _, self.hidden = self.lstm(inputs, self.hidden)\n",
    "        return self.hidden.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        # input size = 1\n",
    "        self.lstm = nn.LSTM(4, hidden_dim, num_layers=num_layers)\n",
    "        self.out = nn.Linear(hidden_dim, 4)\n",
    "    def forward(self, outputs, hidden, criterion):\n",
    "        batch_size, num_steps = outputs.shape\n",
    "        input = torch.tensor([0.0] * batch_size, dtype=torch.double)\n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(num_steps):\n",
    "            # Push current input through LSTM: (seq_len=1, batch_size, input_size=1)\n",
    "            output, hidden = self.lstm(input, hidden)\n",
    "            # Push the output of last step through linear layer; returns (batch_size, 1)\n",
    "            output = self.out(output[-1])\n",
    "            # Generate input for next step by adding seq_len dimension (see above)\n",
    "            input = output.unsqueeze(0)\n",
    "            # Compute loss between predicted value and true value\n",
    "            loss += criterion(output, outputs[:, i])\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(32, 128)\n",
    "decoder = Decoder(128)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, Y in inputs:\n",
    "    X = X.transpose(1,0)\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    encoder.hidden = encoder.init_hidden(X.shape[1])\n",
    "    \n",
    "    hidden = encoder(X)\n",
    "    \n",
    "    loss = decoder(Y, hidden, criterion)\n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses05\n",
      "x\n",
      "11\n",
      "(0, 32)\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "speak = ['Ses01', 'Ses02', 'Ses03', 'Ses04', 'Ses05']\n",
    "#for sp in speak:\n",
    "    #print(sp)\n",
    "    # DATA SET UP\n",
    "le = LabelEncoder()\n",
    "idx_test  = np.where((savez['s'] == 'Ses01') & (savez['t'] == 'impro'))\n",
    "idx_train = np.where((savez['s'] != 'Ses01') & (savez['t'] == 'impro'))\n",
    "    #train_set\n",
    "x_train  = savez['x'][idx_train]    \n",
    "y_train  = k[idx_train]\n",
    "y_train  = le.fit_transform(y_train)    \n",
    "    #test_set\n",
    "x_test   = savez['x'][idx_test]    \n",
    "y_test   = k[idx_test]\n",
    "y_test   = le.fit_transform(y_test) \n",
    "\n",
    "c=0\n",
    "for X, Y in zip(x_train, y_train):\n",
    "    tmp = X.shape\n",
    "    if tmp[0] == 0:\n",
    "        print(sp)\n",
    "        print(\"x\")\n",
    "        print(c)\n",
    "        print(tmp)\n",
    "    c += 1\n",
    "\n",
    "print(\"test\")\n",
    "for X, Y in zip(x_test, y_test):\n",
    "    tmp = X.shape\n",
    "    if tmp[0] == 0:\n",
    "        print(sp)\n",
    "        print(\"x\")\n",
    "        print(c)\n",
    "        print(tmp)\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.delete(x_data, 11)\n",
    "new_y = np.delete(y_data, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 32), dtype=float64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "testt = idx_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3413\n"
     ]
    }
   ],
   "source": [
    "k = []\n",
    "for x in savez['x']:\n",
    "    tmp = x.shape[0]\n",
    "    k.append(tmp)\n",
    "    \n",
    "print(max(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = savez['x'][idx_train]\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max(k), dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2421, 3413, 32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.000000e+00,  0.000000e+00,  0.000000e+00, ...,  0.000000e+00,\n",
       "         0.000000e+00,  0.000000e+00],\n",
       "       [ 0.000000e+00,  0.000000e+00,  0.000000e+00, ...,  0.000000e+00,\n",
       "         0.000000e+00,  0.000000e+00],\n",
       "       [ 0.000000e+00,  0.000000e+00,  0.000000e+00, ...,  0.000000e+00,\n",
       "         0.000000e+00,  0.000000e+00],\n",
       "       ...,\n",
       "       [ 2.933879e-04, -3.839608e+00, -3.601169e+00, ..., -1.583333e-03,\n",
       "         1.606693e-02,  0.000000e+00],\n",
       "       [ 3.002768e-04, -2.573599e+00, -2.166797e+00, ..., -3.916666e-03,\n",
       "         1.507473e-02,  0.000000e+00],\n",
       "       [ 3.190469e-04, -1.724054e+00, -1.454324e+00, ..., -2.833334e-03,\n",
       "         1.049661e-02,  0.000000e+00]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.891660e-04, -5.041446e+00, -4.809515e+00, ...,  2.499999e-03,\n",
       "         7.128459e-03,  0.000000e+00],\n",
       "       [ 6.640420e-04, -5.873871e+00, -5.339462e+00, ...,  4.833334e-03,\n",
       "         7.748954e-03,  0.000000e+00],\n",
       "       [ 6.499290e-04, -7.095003e+00, -5.808956e+00, ...,  8.166669e-03,\n",
       "        -6.283715e-04,  0.000000e+00],\n",
       "       ...,\n",
       "       [ 2.933879e-04, -3.839608e+00, -3.601169e+00, ..., -1.583333e-03,\n",
       "         1.606693e-02,  0.000000e+00],\n",
       "       [ 3.002768e-04, -2.573599e+00, -2.166797e+00, ..., -3.916666e-03,\n",
       "         1.507473e-02,  0.000000e+00],\n",
       "       [ 3.190469e-04, -1.724054e+00, -1.454324e+00, ..., -2.833334e-03,\n",
       "         1.049661e-02,  0.000000e+00]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savez['x'][idx_train][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train  = to_categorical(le.fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2421, 4)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
